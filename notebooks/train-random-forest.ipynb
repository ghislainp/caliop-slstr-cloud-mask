{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime, timezone\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244598\n"
     ]
    }
   ],
   "source": [
    "cloud_dfN = pd.read_parquet(\"../data/caliop-slstr-greenland-maxsza80.parquet\")\n",
    "print(len(cloud_dfN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-04-01 11:29:54+0000', tz='UTC'),\n",
       " Timestamp('2020-09-30 14:44:26+0000', tz='UTC'),\n",
       " 865529,\n",
       " 379069)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = cloud_dfN.Profile_UTC_Time\n",
    "\n",
    "dates.min(), dates.max(), np.sum(dates.dt.year == 2019), np.sum(dates.dt.year == 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-04-01 11:29:54+0000', tz='UTC'),\n",
       " Timestamp('2020-09-30 14:44:26+0000', tz='UTC'),\n",
       " 310423,\n",
       " 934175)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud_dfS = pd.read_parquet(\"../data/caliop-slstr-antarctic-maxsza80.parquet\")\n",
    "print(len(cloud_dfS))\n",
    "\n",
    "dates.min(), dates.max(), np.sum(dates < datetime(2019, 6, 1, tzinfo=timezone.utc)), \\\n",
    "        np.sum(dates > datetime(2019, 6, 1, tzinfo=timezone.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1479720"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud_df = pd.concat((cloud_dfN, cloud_dfS))\n",
    "cloud_df = cloud_df.sample(frac = 1, random_state=7273)\n",
    "\n",
    "cloud_df = cloud_df\n",
    "#cloud_df = cloud_df[cloud_df.file.str.find('S3A') >= 0]\n",
    "len(cloud_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_xy(cloud_df):\n",
    "    data = cloud_df.copy()\n",
    "\n",
    "    data['aa'] = (data['satellite_azimuth_angle'] - data['solar_azimuth_angle']) % 360\n",
    "\n",
    "    inputs = ['S1', 'S2', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9', 'satellite_zenith_angle', 'solar_zenith_angle', 'aa']\n",
    "    X = data[inputs].values\n",
    "\n",
    "    y= cloud = cloud_df['Number_Layers_Found'] > 0\n",
    "    return X, y\n",
    "\n",
    "X, y = get_xy(cloud_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=False\n",
    "\n",
    "#classifier = RandomForestClassifier(n_estimators = 100)\n",
    "classifier = RandomForestClassifier(n_estimators = 5, max_depth = 12, max_leaf_nodes=256) \n",
    "\n",
    "#classifier = DecisionTreeClassifier(max_depth = 10, max_leaf_nodes=50); tree=True\n",
    "    \n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    " \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
    "with open(f\"../models/caliop-random-forest-{date}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(classifier, f)\n",
    "\n",
    "with open(f\"../models/caliop-random-forest-{date}.pkl\", \"rb\") as f:\n",
    "    classifier = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 12\n",
      "511 12\n",
      "511 12\n",
      "511 12\n",
      "511 12\n"
     ]
    }
   ],
   "source": [
    "for c in classifier.estimators_:\n",
    "    n_nodes = c.tree_.node_count\n",
    "    max_depth = c.tree_.max_depth\n",
    "    children_left = c.tree_.children_left\n",
    "    children_right = c.tree_.children_right\n",
    "    feature = c.tree_.feature\n",
    "    threshold = c.tree_.threshold\n",
    "\n",
    "    print(n_nodes, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testN, y_testN = get_xy(cloud_dfN)\n",
    "X_testS, y_testS = get_xy(cloud_dfS)\n",
    "\n",
    "y_predN = classifier.predict(X_testN)\n",
    "y_predS = classifier.predict(X_testS)\n",
    "\n",
    "y_pred_train = classifier.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(y_pred, y_test):\n",
    " \n",
    "    good_detected_cloud = np.sum(y_pred & y_test)\n",
    "    wrong_detected_cloud = np.sum(y_pred & (~y_test))\n",
    "\n",
    "    good_detected_clear = np.sum((~y_pred) & (~y_test))\n",
    "    wrong_detected_clear = np.sum((~y_pred) & y_test)\n",
    "\n",
    "    is_cloud = np.sum(y_test)\n",
    "    is_not_cloud = np.sum(~y_test)\n",
    "\n",
    "    return pd.DataFrame({'TPR': good_detected_cloud / is_cloud, \n",
    "                         'FPR': wrong_detected_cloud / is_not_cloud,\n",
    "                         'TPR_clear': good_detected_clear / is_not_cloud,\n",
    "                         'FPR_clear': wrong_detected_clear / is_cloud}, index=[0]) \n",
    "\n",
    "err = compute_error(y_pred, y_test)\n",
    "err_train = compute_error(y_pred_train, y_train)\n",
    "errN = compute_error(y_predN, y_testN)\n",
    "errS = compute_error(y_predS, y_testS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_ref0 = pd.read_csv(\"Errors/err-reference0.csv\")\n",
    "err_ref1 = pd.read_csv(\"Errors/err-reference1.csv\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(err.FPR, err.TPR, 'o', label='Random Forest (test dataset')\n",
    "plt.plot(err_train.FPR, err_train.TPR, 'x', label='Random Forest (training dataset)')\n",
    "\n",
    "plt.plot(errN.FPR, errN.TPR, 'x', markersize=10, label='Random Forest Greenland')\n",
    "plt.plot(errS.FPR, errS.TPR, 'x', markersize=10, label='Random Forest Antarctic')\n",
    "plt.plot(err_ref0.FPR, err_ref0.TPR, '-k', label='NN Ref0')\n",
    "plt.plot(err_ref0.FPR, err_ref1.TPR, '-.k', label='NN Ref1')\n",
    "\n",
    "plt.plot(0.132132, 0.81991, 's', label=\"SCDA Greenland\")  #  \t0.81991 \t0.132132\n",
    "plt.plot(0.147379, 0.882955, 's', label=\"SCDA Antarctique\")\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.xlabel(\"False positive\")\n",
    "plt.ylabel(\"True positive\")\n",
    "plt.title(\"Cloud detection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
